{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":85316,"databundleVersionId":9635715,"sourceType":"competition"},{"sourceId":9761079,"sourceType":"datasetVersion","datasetId":5977362}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install faiss-cpu\n!pip install -U FlagEmbedding\n!pip install peft","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-30T09:13:32.646838Z","iopub.execute_input":"2024-10-30T09:13:32.647424Z","iopub.status.idle":"2024-10-30T09:14:14.820986Z","shell.execute_reply.started":"2024-10-30T09:13:32.647333Z","shell.execute_reply":"2024-10-30T09:14:14.819865Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nimport pickle\nimport json\nfrom collections import defaultdict\n\nimport faiss\nfrom FlagEmbedding import FlagModel","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:34:50.507276Z","iopub.execute_input":"2024-10-30T09:34:50.508054Z","iopub.status.idle":"2024-10-30T09:34:50.512814Z","shell.execute_reply.started":"2024-10-30T09:34:50.508014Z","shell.execute_reply":"2024-10-30T09:34:50.511754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Load the document embeddings\nwith open('/kaggle/input/m3-embedding-of-512-chunks/chunk_embedding.pkl', 'rb') as f:\n    chunk_embedding_dict = pickle.load(f)\n    \nchunk_ids = list(chunk_embedding_dict.keys())\nchunk_embeddings = np.array([chunk_embedding_dict[chunk_id] for chunk_id in chunk_ids]).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:14:36.457695Z","iopub.execute_input":"2024-10-30T09:14:36.458315Z","iopub.status.idle":"2024-10-30T09:15:13.192090Z","shell.execute_reply.started":"2024-10-30T09:14:36.458280Z","shell.execute_reply":"2024-10-30T09:15:13.191064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Load the test queries\ntest_path = '/kaggle/input/dis-project-1-document-retrieval/test.csv'\ntest_df = pd.read_csv(test_path)\n\n# Load the model\nmodel = FlagModel('BAAI/bge-m3',\n                  query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n                  use_fp16=True)\n\n# Embed the test queries\nqueries = test_df['query'].tolist()\nquery_ids = test_df['id'].tolist()\nquery_embeddings = model.encode(queries).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:15:13.193564Z","iopub.execute_input":"2024-10-30T09:15:13.193986Z","iopub.status.idle":"2024-10-30T09:16:24.988872Z","shell.execute_reply.started":"2024-10-30T09:15:13.193940Z","shell.execute_reply":"2024-10-30T09:16:24.987816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nk = 100  # Number of nearest neighbors to retrieve\n\n# Normalize the corpus matrix\nfaiss.normalize_L2(chunk_embeddings)\n\n# Initialize a FAISS index\nd = chunk_embeddings.shape[1]  # Dimensionality of embeddings\nindex = faiss.IndexFlatIP(d)  # IP = Inner Product, effectively cosine similarity after normalization\nindex.add(chunk_embeddings)  # Add document embeddings to the FAISS index\n\n# Normalize query embeddings\nfaiss.normalize_L2(query_embeddings)\n\n# Perform the search and retrieve top 100 results\ndistances, indices = index.search(query_embeddings, k)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:33:19.845260Z","iopub.execute_input":"2024-10-30T09:33:19.845646Z","iopub.status.idle":"2024-10-30T09:33:59.412759Z","shell.execute_reply.started":"2024-10-30T09:33:19.845608Z","shell.execute_reply":"2024-10-30T09:33:59.411730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map the indices back to document IDs\ntop_k_chunks = {\n    query_id: [chunk_ids[idx] for idx in indices[i]]\n    for i, query_id in enumerate(query_ids)\n}\n\n# Optional: Convert results to a DataFrame for easier access\ntop_k_chunks_df = pd.DataFrame({\n    'id': query_ids,\n    'chunkids': [top_k_chunks[qid] for qid in query_ids]\n})\n\n# Display the top results\ntop_k_chunks_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:38:04.061689Z","iopub.execute_input":"2024-10-30T09:38:04.062576Z","iopub.status.idle":"2024-10-30T09:38:04.173020Z","shell.execute_reply.started":"2024-10-30T09:38:04.062534Z","shell.execute_reply":"2024-10-30T09:38:04.171984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rank_and_aggregate(df, aggregate_num=10):\n    results = {}\n\n    # Loop through each query's candidates\n    for _, row in df.iterrows():\n        doc_scores = defaultdict(float)\n        query_id = row['id']\n        chunks = row['chunkids']\n\n        # Weight each chunk based on its position in the list (higher rank -> higher weight)\n        for rank, chunk_id in enumerate(chunks, start=1):\n            # Extract the document ID part (everything before \"_chunk\")\n            doc_id = \"_\".join(chunk_id.split(\"_\")[:-2])\n            # Calculate weight, for example, inversely proportional to the rank\n            score = 1 / rank  # Adjust the weighting function if needed\n\n            # Aggregate scores for each document\n            doc_scores[doc_id] += score\n\n        # Get the top 10 documents based on cumulative scores\n        top_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)[:aggregate_num]\n        results[query_id] = [doc for doc, score in top_docs]\n\n    # Convert results to DataFrame for easier access\n    top_results_df = pd.DataFrame(list(results.items()), columns=['id', 'docids'])\n    return top_results_df\n\n# Apply the function\ntop_results_df = rank_and_aggregate(top_k_chunks_df)\ntop_results_df.head()  # Display the top results","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:38:08.189817Z","iopub.execute_input":"2024-10-30T09:38:08.190564Z","iopub.status.idle":"2024-10-30T09:38:08.647116Z","shell.execute_reply.started":"2024-10-30T09:38:08.190525Z","shell.execute_reply":"2024-10-30T09:38:08.645913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the submission DataFrame\nsubmission_df = pd.DataFrame(top_results_df)\n\n# Save the submission file\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:38:13.072445Z","iopub.execute_input":"2024-10-30T09:38:13.073426Z","iopub.status.idle":"2024-10-30T09:38:13.103079Z","shell.execute_reply.started":"2024-10-30T09:38:13.073374Z","shell.execute_reply":"2024-10-30T09:38:13.102169Z"},"trusted":true},"execution_count":null,"outputs":[]}]}