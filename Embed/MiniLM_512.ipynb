{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9757413,"sourceType":"datasetVersion","datasetId":5974667}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install and Import","metadata":{}},{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-10-30T00:03:30.801440Z","iopub.execute_input":"2024-10-30T00:03:30.801953Z","iopub.status.idle":"2024-10-30T00:03:44.327198Z","shell.execute_reply.started":"2024-10-30T00:03:30.801915Z","shell.execute_reply":"2024-10-30T00:03:44.326236Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport pickle\nimport torch\nfrom sentence_transformers import SentenceTransformer\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Embed Chunks (512)\n\nWe load the pre-chunked documents (chunk size 512) and embed them with the MiniLM embedder.","metadata":{}},{"cell_type":"code","source":"# Load the JSON file with chunks\nchunk_json_path = '/kaggle/input/chunk-doc-512/chunk_doc_512.json'\nwith open(chunk_json_path, 'r') as f:\n    chunk_doc_index = json.load(f)\n\n# Prepare the embedder (using MiniLM-L6-v2 model) and switch to GPU if available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = SentenceTransformer('paraphrase-MiniLM-L6-v2', device=device)\n\n# Convert chunks into a list for easy embedding\nchunk_texts = list(chunk_doc_index.values())\nchunk_ids = list(chunk_doc_index.keys())\n\n# Define batch size based on memory availability and initialize variables\nbatch_size = 32  # Adjust based on your system memory (64 is safe for moderate memory)\nembeddings = []\nsaved_batches = 0\ntotal_chunks = len(chunk_texts)\n\n# Embed in batches and save periodically to avoid memory overload\nfor i in tqdm(range(0, total_chunks, batch_size), desc=\"Embedding Chunks\"):\n    # Get the current batch\n    batch_texts = chunk_texts[i:i + batch_size]\n    batch_ids = chunk_ids[i:i + batch_size]\n\n    # Encode the batch\n    batch_embeddings = model.encode(batch_texts, batch_size=batch_size, show_progress_bar=False)\n    \n    # Convert embeddings to list and pair with chunk IDs\n    batch_data = {batch_ids[j]: batch_embeddings[j].tolist() for j in range(len(batch_ids))}\n    \n    # Append to embeddings list\n    embeddings.append(batch_data)\n\n    # Save intermediate batches to .pkl every 100,000 chunks\n    if (i // batch_size) % (50000 // batch_size) == 0 and i > 0:\n        with open(f'/kaggle/working/chunk_embeddings_batch_{saved_batches}.pkl', 'wb') as pkl_file:\n            pickle.dump(embeddings, pkl_file)\n        saved_batches += 1\n        embeddings = []  # Clear memory by resetting the embeddings list\n\n# Save any remaining batches\nif embeddings:\n    with open(f'/kaggle/working/chunk_embeddings_batch_{saved_batches}.pkl', 'wb') as pkl_file:\n        pickle.dump(embeddings, pkl_file)\n\nprint(\"Embedding process completed and saved in batches as .pkl files.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T00:11:17.562784Z","iopub.execute_input":"2024-10-30T00:11:17.563160Z","iopub.status.idle":"2024-10-30T00:31:05.533340Z","shell.execute_reply.started":"2024-10-30T00:11:17.563123Z","shell.execute_reply":"2024-10-30T00:31:05.532013Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Merge Embeddings\n\nGiven the memory constraint, the embeddings were saved in separate files. Next we'll merge them in one for future use.","metadata":{}},{"cell_type":"code","source":"# Directory where all the chunk embedding .pkl files are saved\nembedding_dir = '/kaggle/working/'\n\n# List all .pkl files related to chunk embeddings\npkl_files = sorted([f for f in os.listdir(embedding_dir) if f.startswith(\"chunk_embeddings_batch_\") and f.endswith(\".pkl\")])\n\n# Initialize an empty dictionary to store all embeddings\nmerged_embeddings = {}\n\n# Load each .pkl file and merge contents\nfor pkl_file in pkl_files:\n    with open(os.path.join(embedding_dir, pkl_file), 'rb') as f:\n        batch_data = pickle.load(f)\n        merged_embeddings.update(batch_data)  # Merge dictionaries\n\n# Save the merged embeddings into a single .pkl file\nwith open('/kaggle/working/merged_chunk_embeddings.pkl', 'wb') as merged_file:\n    pickle.dump(merged_embeddings, merged_file)\n\nprint(\"All embeddings have been merged and saved as merged_chunk_embeddings.pkl\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T12:26:38.595625Z","iopub.execute_input":"2024-10-30T12:26:38.595897Z","iopub.status.idle":"2024-10-30T12:26:38.609577Z","shell.execute_reply.started":"2024-10-30T12:26:38.595866Z","shell.execute_reply":"2024-10-30T12:26:38.608656Z"},"trusted":true},"outputs":[{"name":"stdout","text":"All embeddings have been merged and saved as merged_chunk_embeddings.pkl\n","output_type":"stream"}],"execution_count":1}]}